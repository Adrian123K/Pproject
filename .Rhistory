install.packages("KoNLP")
library(KoNLP)
library(plyr)
setwd('d:/D:\Pproject')
setwd('d:/Pproject')
getwd()
hd=readLines("headline.txt")
hd
setwd('d:/Pproject')
getwd()
hd=readLines("headline.txt")
hd
hd=readLines("headline.txt")
hd
hd=readLines("headline.txt",encoding='utf-8')
hd
hd=readLines("headline.txt",encoding='utf-8')
hd
library(data.table)
hd <- fread("headline.txt",encoding='utf-8')
hd
Sys.setlocale('LC_CTYPE','ko_KR.UTF-8')
hd <- readLines("headline.txt",encoding='utf-8')
hd
hd <- readLines("headline.txt",encoding='cp949')
hd
hd <- readLines("headline.txt",encoding='utf-8')
hd <- readLines("test.txt",encoding='utf-8')
hd
hd <- readLines("test.txt",encoding='euc-kr')
hd
hd
hd <- readLines("test.txt")
hd
hd_exn
# 1. 데이터에서 단어만 추출
hd_exn=sapply(hd, extractNoun, USE.NAMES=F)
hd_exn
library(googleVis)
library(devtools)
library(lubridate)
library(stringr)
library(ggplot2)
library(rJava) # 안되는 라이브는 삭제 후 다시
library(RColorBrewer)
library(wordcloud)
library(dplyr)
# 1. 데이터에서 단어만 추출
hd_exn=sapply(hd, extractNoun, USE.NAMES=F)
library(KoNLP)
# 1. 데이터에서 단어만 추출
hd_exn=sapply(hd, extractNoun, USE.NAMES=F)
hd_exn
# 2. 단어 집합 생성
head(unlist(hd_exn),30)
hd_unl=unlist(hd_exn)
hd_unl
# 3. 단어 필터링
# 4. 단어 핸들링
# gsub("변경 전 글자", "변경 후 글자", "원본데이터")
hd_unl=gsub("\\d+","",hd_unl)
hd_unl=gsub("들","",hd_unl)
hd_unl=gsub("저","나",hd_unl)
hd_unl=gsub("내","나",hd_unl)
hd_unl=gsub("나","자신",hd_unl)
hd_unl=gsub("해","",hd_unl)
hd_unl=gsub("곳","",hd_unl)
hd_unl=gsub("한","",hd_unl)
hd_unl=gsub("것","",hd_unl)
hd_unl=gsub("돌","",hd_unl)
hd_unl=gsub("이","",hd_unl)
hd_unl=gsub("름","",hd_unl)
source('D:/R/ppp.R', encoding = 'UTF-8', echo=TRUE)
install.packages("KoNLP")
# 5. txt파일로 저장하고 table로 불러오면서 공백제거
write(unlist(hd_unl),"headline_unlist.txt")
hd_list=read.table("headline_unlist.txt")
hd_list
# 3. 단어 필터링
# 4. 단어 핸들링
# gsub("변경 전 글자", "변경 후 글자", "원본데이터")
hd_unl=Filter(function(x){
nchar(x)<=10
}, hd_unl)
hd_unl
hd_unl <- Filter(function(x){
nchar(x)>=2
}, hd_unl)
hd_unl
hd_unl=gsub("\\d+","",hd_unl)
hd_unl
# 5. txt파일로 저장하고 table로 불러오면서 공백제거
write(unlist(hd_unl),"headline_unlist.txt")
hd_list=read.table("headline_unlist.txt")
hd_list
# 6. 단어 빈도수 저장
nrow(hd_list)
wc=table(hd_list)
# 7. wordcloud 출력
pal=brewer.pal(9,"Set3")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
legend(0.3,1,"1Q News Head", cex=0.8, fill=NA, border=NA, bg='white', text.col='red', text.font=2, box.col='red')
hd_txt <- readLines('head_gsub.txt')
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
hd_unl
hd_unl=gsub(" ","",hd_unl)
hd_unl
# 5. txt파일로 저장하고 table로 불러오면서 공백제거
write(unlist(hd_unl),"headline_unlist.txt")
hd_list=read.table("headline_unlist.txt")
hd_list
# 6. 단어 빈도수 저장
nrow(hd_list)
wc=table(hd_list)
wc
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
warnings()
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
nrow(hd_list)
wc=table(hd_list)
head(sort(wc,decreasing=T),20)
hd <- readLines("test.txt")
hd_exn=sapply(hd, extractNoun, USE.NAMES=F)
head(unlist(hd_exn),30)
hd_unl=unlist(hd_exn)
hd_unl
hd_unl <- Filter(function(x){
nchar(x)<=10
}, hd_unl)
hd_unl <- Filter(function(x){
nchar(x)>=2
}, hd_unl)
hd_unl
hd_unl=gsub("\\d+","",hd_unl)
hd_unl=gsub(" ","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
nrow(hd_list)
wc=table(hd_list)
head(sort(wc,decreasing=T),20)
pal=brewer.pal(9,"Set3")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
hd <- readLines("headline2Q.txt")
hd
hd <- readLines("headline2Q.txt",encoding='ANSI')
hd
hd <- readLines("test2.txt")
hd
hd_exn=sapply(hd, extractNoun, USE.NAMES=F)
head(unlist(hd_exn),30)
hd_unl=unlist(hd_exn)
hd_unl
hd_unl <- Filter(function(x){
nchar(x)<=10
}, hd_unl)
hd_unl <- Filter(function(x){
nchar(x)>=2
}, hd_unl)
hd_unl
hd_unl=gsub("\\d+","",hd_unl)
hd_unl=gsub(" ","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
nrow(hd_list)
wc=table(hd_list)
head(sort(wc,decreasing=T),20)
pal=brewer.pal(9,"Set3")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
hd_txt <- readLines('head_gsub.txt')
hd_txt
hd <- readLines("test2.txt")
hd
hd_exn=sapply(hd, extractNoun, USE.NAMES=F)
head(unlist(hd_exn),30)
hd_unl=unlist(hd_exn)
hd_unl
hd_unl <- Filter(function(x){
nchar(x)<=10
}, hd_unl)
hd_unl <- Filter(function(x){
nchar(x)>=2
}, hd_unl)
hd_unl
hd_unl=gsub("\\d+","",hd_unl)
hd_unl=gsub(" ","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
nrow(hd_list)
wc=table(hd_list)
head(sort(wc,decreasing=T),20)
pal=brewer.pal(9,"Set3")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
hd_unl=gsub("LG","",hd_unl)
hd_unl=gsub("G","",hd_unl)
hd_unl=gsub("전자","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
nrow(hd_list)
wc=table(hd_list)
head(sort(wc,decreasing=T),20)
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
hd <- readLines("test.txt")
hd_exn <- sapply(hd, extractNoun, USE.NAMES=F)
head(unlist(hd_exn),30)
hd_unl <- unlist(hd_exn)
hd_unl <- Filter(function(x){
nchar(x)<=10
}, hd_unl)
hd_unl <- Filter(function(x){
nchar(x)>=2
}, hd_unl)
hd_unl <- gsub("\\d+","",hd_unl)
hd_unl <- gsub(" ","",hd_unl)
hd_unl <- gsub("LG","",hd_unl)
hd_unl <- gsub("G","",hd_unl)
hd_unl <- gsub("전자","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
nrow(hd_list)
wc <- table(hd_list)
head(sort(wc,decreasing=T),10)
pal=brewer.pal(9,"Set3")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
#legend(0.3,1,"1Q News Head", cex=0.8, fill=NA, border=NA, bg='white', text.col='red', text.font=2, box.col='red')
pal=brewer.pal(9,"Set2")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
pal=brewer.pal(8,"Set2")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
pal=brewer.pal(8,"Set1")
head(sort(wc,decreasing=T),10)
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
pal=brewer.pal(7,"Set1")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
pal=brewer.pal(6,"Set1")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
hd_unl <- gsub("속보","",hd_unl)
hd_unl <- gsub("\\d+","",hd_unl)
hd_unl <- gsub(" ","",hd_unl)
hd_unl <- gsub("LG","",hd_unl)
hd_unl <- gsub("G","",hd_unl)
hd_unl <- gsub("전자","",hd_unl)
hd_unl <- gsub("속보","",hd_unl)
hd_unl <- gsub("전자","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
wc <- table(hd_list)
head(sort(wc,decreasing=T),10)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
wc <- table(hd_list)
head(sort(wc,decreasing=T),10)
hd_unl <- gsub("s","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
wc <- table(hd_list)
head(sort(wc,decreasing=T),10)
hd <- readLines("test.txt")
hd_exn <- sapply(hd, extractNoun, USE.NAMES=F)
head(unlist(hd_exn),30)
hd_unl <- unlist(hd_exn)
hd_unl <- Filter(function(x){
nchar(x)<=10
}, hd_unl)
hd_unl <- Filter(function(x){
nchar(x)>=2
}, hd_unl)
hd_unl <- gsub("\\d+","",hd_unl)
hd_unl <- gsub(" ","",hd_unl)
hd_unl <- gsub("LG","",hd_unl)
hd_unl <- gsub("G","",hd_unl)
hd_unl <- gsub("전자","",hd_unl)
hd_unl <- gsub("속보","",hd_unl)
hd_unl <- gsub("전자","",hd_unl)
hd_unl <- gsub("s","",hd_unl)
hd_txt <- readLines('head_gsub.txt')
cnt <- length(hd_txt)
for(i in 1:cnt){
hd_unl=gsub((hd_txt[i]),"",hd_unl)
}
write(unlist(hd_unl),"headline_unlist.txt")
hd_list <- read.table("headline_unlist.txt")
wc <- table(hd_list)
head(sort(wc,decreasing=T),10)
pal=brewer.pal(6,"Set2")
wordcloud(names(wc), freq=wc, scale=c(5,1), rot.per=0.25, min.freq=1, random.order=F, random.color=T, colors=pal)
wc
